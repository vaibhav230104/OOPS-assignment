{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090dab19-cff9-4636-8dc0-25015a18ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "# Web Scraping is the automated process of extracting information or data from websites. It's used to gather data that might not be available through conventional means or APIs. Three areas where Web Scraping is commonly used:\n",
    "# - Business and Market Research: Gathering data for competitive analysis, pricing, and market trends.\n",
    "# - Academic Research: Collecting data for research purposes or gathering information from various sources.\n",
    "# - Real-time Data Aggregation: Obtaining updated information such as weather forecasts, news updates, etc.\n",
    "\n",
    "# Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "# Different methods for Web Scraping include:\n",
    "# - Using libraries like BeautifulSoup, Scrapy in Python.\n",
    "# - Utilizing browser extensions or plugins for manual scraping.\n",
    "# - Employing headless browsers like Puppeteer or Selenium.\n",
    "\n",
    "# Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "# Beautiful Soup is a Python library used for parsing HTML and XML documents. It provides tools for navigating, searching, and modifying parsed HTML/XML content. It's used in Web Scraping to extract required data from HTML by parsing the document and navigating through its structure.\n",
    "\n",
    "# Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "# Flask is used in the Web Scraping project to create a web application. It can serve as a platform to display scraped data, enabling users to access and interact with the extracted information through a user-friendly interface. Additionally, Flask can facilitate the integration of scraping functionalities with other services or databases.\n",
    "\n",
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "# Possible AWS services used in a Web Scraping project might include:\n",
    "# - AWS Lambda: For serverless execution of scraping scripts, reducing operational overhead.\n",
    "# - AWS S3: Storing scraped data in buckets for easy access and retrieval.\n",
    "# - AWS EC2: Hosting a web application built with Flask to display scraped data.\n",
    "# - AWS CloudWatch: Monitoring and logging service to track scraping activities and application performance.\n",
    "# - AWS IAM: Managing access to AWS services securely by creating users, roles, and policies.\n",
    "\n",
    "# Each service has its role: Lambda for executing scraping scripts, S3 for data storage, EC2 for hosting, CloudWatch for monitoring, and IAM for managing access control.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
